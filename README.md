ğŸ“˜ Quantitative Risk Modeling â€” Credit Risk & FICO Score QuantizationJPMC Quantitative Research Virtual Experience ProgramThis repository contains my completed solutions for Task 3 and Task 4 of the JPMorgan Chase Quantitative Research Virtual Experience Program, focused on credit risk modeling, probability of default (PD) estimation, and FICO credit score quantization techniques used in retail banking and risk analytics.ğŸ“Œ OverviewThe project consists of two major components:ğŸ”¹ Task 3 â€” Credit Risk Analysis & PD ModelingğŸ¯ Objective:Build a predictive model that estimates the Probability of Default (PD) for each borrower based on their financial characteristics.ğŸ“Š Features used:IncomeTotal loans outstandingFICO scoreLoan-to-income ratioPast default historyOther customer-level featuresğŸ¤– Models Implemented:Logistic RegressionRandom Forest ClassifierGradient Boosting ClassifierXGBoost (if available)ğŸ“ˆ Analysis Performed:Feature distributionsCorrelation heatmapsROC & AUC comparisonPD calibrationError analysisExpected Loss computation:$$EL = PD \times LGD \times EAD$$LGD (Loss Given Default): 90% (10% recovery rate)EAD (Exposure At Default): Loan amountâœ… Output:A clean function to predict loss:def predict_expected_loss(borrower_features):
    """
    Returns the expected monetary loss for a given borrower.
    Formula: PD * LGD * EAD
    """
    return expected_loss
ğŸ”¹ Task 4 â€” Optimal FICO Score QuantizationğŸ¯ Objective:FICO scores must be converted into categorical risk buckets for modeling architectures that require discrete labels.â˜‘ Methods Implemented:1ï¸âƒ£ K-Means Quantization (Primary Method)Fast and stableMinimizes mean squared error (MSE)Uses AIC/BIC to choose optimal number of bucketsProduces continuous-to-categorical mappingProvides clean and interpretable boundariesVisuals included:FICO distribution histogramSmoothed PD vs. FICO plotAIC/BIC/MSE model selection curvesBucket boundary visualization2ï¸âƒ£ Dynamic Programming Log-Likelihood Optimization (Theory Section)Dynamic programming gives globally optimal buckets by maximizing:$$LL = \sum_{i=1}^{B} \left[ k_i \ln(p_i) + (n_i - k_i)\ln(1 - p_i) \right]$$Constraints:Complexity is $O(N^2)$ to $O(N^3)$Not feasible for large datasetsNot expected to be computed fully in this program, but included for theoretical completeness.Included in the notebook:Full explanation of DP formulationOptimized pseudocodeA tiny runnable DP demo (20 rows) to illustrate the logicğŸ§  Key Insightsâ­ From Task 3:Income, past defaults, and loan-to-income are critical PD predictors.Ensemble models generally outperform simple linear models in capturing non-linear risk factors.Expected loss estimation ties PD directly to financial risk.â­ From Task 4:K-Means is the most practical quantization method for large datasets.DP is theoretically optimal but computationally heavy.Final bucket boundaries must be monotonic and risk-aligned to be useful for business rules.ğŸ“‚ Repository Structureâ”œâ”€â”€ Task3_Credit_Risk_Modeling.ipynb
â”œâ”€â”€ Task4_FICO_Quantization.ipynb
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Task 3 and 4_Loan_Data.csv
â”œâ”€â”€ README.md
â””â”€â”€ outputs/
    â”œâ”€â”€ PD_model.pkl
    â”œâ”€â”€ kmeans_bucket_map.csv
    â””â”€â”€ evaluation_plots/
ğŸš€ How to Run1ï¸âƒ£ Install Requirementspip install numpy pandas scikit-learn seaborn matplotlib xgboost
2ï¸âƒ£ Launch Jupyter Notebookjupyter notebook
3ï¸âƒ£ Run All CellsOpen and run:Task3_Credit_Risk_Modeling.ipynbTask4_FICO_Quantization.ipynbğŸ† About the ProgramThis work was completed as part of the
